Q1:
π = [0.5  0.5]
A = [0.5  0.5
     0.5  0.5]
B = [0.9  0.1
     0.5  0.5]

Q2:
The result of multiplying the transition matrix with the current estimate
of states is a new row vector that represents the updated estimate of the
state distribution. This new vector will have the same number of entries
as the original vector, and each entry will represent the updated 
probability of being in a given state (in this case, the probability
of using coin 1 or coin 2 at the current time step). The entries in 
the new vector will be computed by multiplying the corresponding 
entries in the transition matrix and the original vector, and summing
the resulting values across the columns of the transition matrix.

Q3:
The result of this operation is a new row vector that represents the 
updated estimate of the probabilities of observing each outcome. 
This vector will have the same number of entries as the original vector
and each entry will represent the updated probability of observing a 
given outcome (head or tail) at the current time step

Q4: 
When we condition on the state Xt=xi, this means that we are considering 
a specific value of the state variable at time t. Because the value of the 
state variable is fixed at this specific value, we can substitute O1:t=o1:t
with Ot=ot without changing the meaning of the expression. This is because
the value of the state variable at time t is the same in both expressions, 
so the overall meaning of the expression remains the same.

Q5:
if the HMM has N states and the observed data consists of T time steps, 
then the matrix δ would have dimensions NxT, and would therefore have NxT 
values. Similarly, the matrix δi d x would also have dimensions NxT.cd -



Q6: 
The di-gamma function, also known as the digamma function,
is a mathematical function that is often used in statistics
and probability theory. In this context, the sum of the 
alphas in the di-gamma function is used as a normalizing 
constant, which ensures that the output of the function is
a valid probability distribution. By dividing the output of
the di-gamma function by the sum of the alphas, we can ensure
that the probabilities sum to 1, which is a necessary 
property of any valid probability distribution. This
normalization is important because it allows us to make
probabilistic predictions based on the output of the di-gamma function.

Q10: Baum-Welch uniform 
Initializing the Baum-Welch algorithm with a uniform distribution can
affect the learning in a number of ways. One way that it can affect 
the learning is by providing a starting point for the algorithm to 
begin its iterative process of estimating the parameters of the hidden
Markov model. If the initial distribution is not uniform, the algorithm
may converge to a different set of parameters than if it were 
initialized with a uniform distribution. This can affect the performance
of the model in terms of its ability to accurately model the data.

Q10: diagonal A matrix and π= [0, 0, 1]
the diagonal A matrix and π = [0, 0, 1] may encode certain assumptions 
or constraints about the structure of the model, which can affect the 
learning process. For example, the diagonal A matrix may indicate that
the model is assuming that the transition probabilities between states
are independent of each other, while the value of π = [0, 0, 1] may
indicate that the model is assuming that the initial state is the third state in the model.
